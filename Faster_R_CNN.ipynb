{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Faster_R_CNN.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"t1bMHM2-GTdl"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DJTy2Ypc4aaI"},"source":["$$\\lim_{a\\to\\frac{\\pi}{4}}\\frac{\\frac{d}{da}\\left(\\sin{a}+-6\\sec{a}\\right)}{\\frac{d}{da}\\left(a+-4\\frac{\\pi}{4}\\right)}$$"]},{"cell_type":"code","metadata":{"id":"hd7Q6awqMZwt"},"source":["%cd gdrive/MyDrive/faster"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9LSXly4GXaj"},"source":["import pandas as pd\r\n","import numpy as np\r\n","import cv2\r\n","import os\r\n","import re\r\n","import ast\r\n","import random\r\n","import datetime\r\n","import pickle\r\n","import time\r\n","import errno\r\n","import math\r\n","import sys\r\n","\r\n","from PIL import Image\r\n","\r\n","import matplotlib.pyplot as pp\r\n","import albumentations as A\r\n","import transforms as T\r\n","from collections import defaultdict, deque\r\n","from albumentations.pytorch.transforms import ToTensor\r\n","from google.colab.patches import cv2_imshow\r\n","\r\n","import torch\r\n","import torchvision\r\n","import torch.distributed as dist\r\n","\r\n","from torchvision.transforms import functional as F\r\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\r\n","from torchvision.models.detection import FasterRCNN\r\n","import torchvision.models.detection.mask_rcnn\r\n","from torchvision.models.detection.rpn import AnchorGenerator\r\n","\r\n","from torch.utils.data import DataLoader, Dataset\r\n","from torch.utils.data.sampler import SequentialSampler\r\n","\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib.patches as patches\r\n","\r\n","from tqdm import tqdm\r\n","\r\n","from engine import train_one_epoch, evaluate\r\n","import utils"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bdV_itDQD3yV"},"source":["os.chdir('/content/gdrive/MyDrive/faster')\r\n","try:\r\n","    os.remove('result.csv')\r\n","except:\r\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F3_swvX3GsRU"},"source":["DIR_INPUT = '/content/gdrive/MyDrive/ocr-data/ocr-data/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9EwrvgXPGuEU"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R4H_klvUGvzl"},"source":["train_df = pd.read_csv(f'{DIR_INPUT}batch_1/JSON/csv_1.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvVRZBMxG7tq"},"source":["def make_float(df):\r\n","    df['x'] = df['x'].astype(np.float)\r\n","    df['y'] = df['y'].astype(np.float)\r\n","    df['w'] = df['w'].astype(np.float)\r\n","    df['h'] = df['h'].astype(np.float)\r\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPK8bE8vG-5b"},"source":["train_df = make_float(train_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_GBCD2E7LdQ"},"source":["visible_latex_chars = train_df['visible_latex_chars'].unique()\r\n","visible_char_map = train_df['visible_char_map'].unique()\r\n","\r\n","char_to_map = {}\r\n","map_to_char = {}\r\n","\r\n","first_iter = 0\r\n","for each_latex_chars in visible_latex_chars:\r\n","    each_latex_chars = ast.literal_eval(each_latex_chars)\r\n","    each_latex_map = ast.literal_eval(visible_char_map[first_iter])\r\n","    for second_iter in range(len(each_latex_chars)):\r\n","        char_to_map[each_latex_chars[second_iter]] = each_latex_map[second_iter]\r\n","        map_to_char[each_latex_map[second_iter]] = each_latex_chars[second_iter]\r\n","    first_iter += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7yFV_XPsHBo8"},"source":["class ExpressionDataset(Dataset):\r\n","\r\n","    def __init__(self, dataframe, image_dir, transforms=None):\r\n","        super().__init__()\r\n","        \r\n","        self.df = dataframe\r\n","        self.filenames = dataframe['filename'].unique()\r\n","        self.image_dir = image_dir\r\n","        self.transforms = transforms\r\n","\r\n","    def __getitem__(self, index: int):\r\n","\r\n","        filename = self.filenames[index]\r\n","        records = self.df[self.df['filename'] == filename]\r\n","        maps = ast.literal_eval(records['visible_char_map'].unique()[0])\r\n","\r\n","        image = cv2.imread(f'{self.image_dir}/batch_1/background_images/{filename}', cv2.COLOR_BGR2GRAY)\r\n","        image = image.astype(np.float32)\r\n","        image /= 255.0\r\n","        image = np.around(image)\r\n","        image *= 255.0\r\n","        image /= 255.0\r\n","\r\n","        #image = cv2.imread(f'{self.image_dir}/batch_1/background_images/{filename}', cv2.IMREAD_COLOR)\r\n","        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\r\n","        #image /= 255.0\r\n","\r\n","        boxes = records[['x', 'y', 'w', 'h']].values\r\n","        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\r\n","        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\r\n","\r\n","        boxes = torch.as_tensor(boxes, dtype=torch.float32)\r\n","        \r\n","        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\r\n","        area = torch.as_tensor(area, dtype=torch.float32)\r\n","\r\n","        labels = torch.tensor(maps,dtype = torch.int64)\r\n","        \r\n","        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\r\n","        \r\n","        target = {}\r\n","        target['boxes'] = boxes\r\n","        target['labels'] = labels\r\n","        # target['masks'] = None\r\n","        target['image_id'] = torch.tensor([index])\r\n","        target['area'] = area\r\n","        target['iscrowd'] = iscrowd\r\n","\r\n","        if self.transforms is not None:\r\n","            image, target = self.transforms(image, target)\r\n","\r\n","        return image, target\r\n","\r\n","    def __len__(self) -> int:\r\n","        return self.filenames.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oI3ICqH7HEoG"},"source":["def get_transform(train):\r\n","    transforms = []\r\n","    transforms.append(T.ToTensor())\r\n","    #if train:\r\n","        # (역자주: 학습시 50% 확률로 학습 영상을 좌우 반전 변환합니다)\r\n","        #transforms.append(T.RandomHorizontalFlip(0.5))\r\n","    return T.Compose(transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WryYCGWnMiHs"},"source":["dataset = ExpressionDataset(train_df,DIR_INPUT,get_transform(train=True))\r\n","dataset_test = ExpressionDataset(train_df,DIR_INPUT,get_transform(train=False))\r\n","\r\n","indices = torch.randperm(len(dataset)).tolist()\r\n","dataset = torch.utils.data.Subset(dataset, indices[:-2000])\r\n","dataset_test = torch.utils.data.Subset(dataset_test, indices[-2000:])\r\n","\r\n","data_loader = torch.utils.data.DataLoader(\r\n","        dataset, batch_size=1, shuffle=True, num_workers=4,\r\n","        collate_fn=utils.collate_fn)\r\n","\r\n","data_loader_test = torch.utils.data.DataLoader(\r\n","        dataset_test, batch_size=1, shuffle=False, num_workers=4,\r\n","        collate_fn=utils.collate_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x04_99GQKy0d"},"source":["# load a model; pre-trained on COCO\r\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EqW78emzKcH-"},"source":["num_classes = 81  # 1 class (wheat) + background\r\n","\r\n","# get number of input features for the classifier\r\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\r\n","\r\n","# replace the pre-trained head with a new one\r\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"16af19VrLMxU"},"source":["model.to(device)\r\n","params = [p for p in model.parameters() if p.requires_grad]\r\n","optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\r\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\r\n","\r\n","num_epochs = 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OEWBSfMsLSfW"},"source":["for epoch in range(num_epochs):\r\n","    # 1 에포크동안 학습하고, 10회 마다 출력합니다\r\n","    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\r\n","    # 학습률을 업데이트 합니다\r\n","    lr_scheduler.step()\r\n","    # 테스트 데이터셋에서 평가를 합니다\r\n","    evaluate(model, data_loader_test, device=device)\r\n","\r\n","print(\"That's it!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AoSBF_C8VzpI"},"source":["torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUEm6lOg6iYV"},"source":["images, targets = next(iter(data_loader_test))\r\n","images = list(image.to(device) for image in images)\r\n","targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\r\n","\r\n","images = list(img.to(device) for img in images)\r\n","\r\n","sample = images[0].permute(1,2,0).cpu().numpy()\r\n","\r\n","model.eval()\r\n","outputs = model(images)\r\n","\r\n","cpu_device = torch.device(\"cpu\")\r\n","outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\r\n","\r\n","empty_string = ''\r\n","for x in outputs[0]['labels'].tolist():\r\n","    empty_string += map_to_char[x]\r\n","\r\n","print(empty_string)\r\n","\r\n","fig, ax = plt.subplots(1, 1, figsize=(16, 8))\r\n","ax.imshow(sample)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MSk0f_qqlN0"},"source":["def format_prediction_string(boxes, scores):\r\n","    pred_strings = []\r\n","    for j in zip(scores, boxes):\r\n","        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\r\n","\r\n","    return \" \".join(pred_strings)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYJTZFpHlwZ_"},"source":["results = []\r\n","detection_threshold = 0.6\r\n","for images, image_ids in data_loader_test:\r\n","\r\n","    images = list(image.to(device) for image in images)\r\n","    outputs = model(images)\r\n","\r\n","    for i, image in enumerate(images):\r\n","\r\n","        boxes = outputs[i]['boxes'].data.cpu().numpy()\r\n","        scores = outputs[i]['scores'].data.cpu().numpy()\r\n","        \r\n","        boxes = boxes[scores >= detection_threshold].astype(np.int32)\r\n","        scores = scores[scores >= detection_threshold]\r\n","        image_id = image_ids[i]\r\n","        \r\n","        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\r\n","        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\r\n","        \r\n","        result = {\r\n","            'image_id': image_id,\r\n","            'PredictionString': format_prediction_string(boxes, scores)\r\n","        }\r\n","\r\n","        \r\n","        results.append(result)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sCAXbW42YRXv"},"source":["import matplotlib.pyplot as plt\r\n","import matplotlib.patches as patches\r\n","from PIL import Image\r\n","import numpy as np\r\n","\r\n","im = sample = images[0].permute(1,2,0).cpu().numpy().astype(np.float64)\r\n","\r\n","boxes = outputs[0]['boxes'].data.cpu().numpy()\r\n","scores = outputs[0]['scores'].data.cpu().numpy()\r\n","\r\n","boxes = boxes[scores >= detection_threshold].astype(np.int32)\r\n","# Create figure and axes\r\n","fig,ax = plt.subplots(1)\r\n","\r\n","# Display the image\r\n","ax.imshow(im)\r\n","\r\n","# Create a Rectangle patch\r\n","for box in boxes:\r\n","    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=1,edgecolor='r',facecolor='none')\r\n","    ax.add_patch(rect)\r\n","\r\n","# Add the patch to the Axes\r\n","ax.add_patch(rect)\r\n","\r\n","plt.show()"],"execution_count":null,"outputs":[]}]}